{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vignesh t\\appdata\\roaming\\python\\python311\\site-packages (1.26.3)\n",
      "Requirement already satisfied: pulp in c:\\python311\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: streamlit in c:\\python311\\lib\\site-packages (1.31.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python311\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\python311\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\python311\\lib\\site-packages (from streamlit) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\python311\\lib\\site-packages (from streamlit) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\python311\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<8,>=1.4 in c:\\users\\vignesh t\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (6.11.0)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\python311\\lib\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\python311\\lib\\site-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\python311\\lib\\site-packages (from streamlit) (4.25.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\python311\\lib\\site-packages (from streamlit) (15.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\python311\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\python311\\lib\\site-packages (from streamlit) (13.7.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\python311\\lib\\site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\python311\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\python311\\lib\\site-packages (from streamlit) (4.9.0)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\python311\\lib\\site-packages (from streamlit) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\python311\\lib\\site-packages (from streamlit) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\python311\\lib\\site-packages (from streamlit) (3.1.41)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\python311\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\python311\\lib\\site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\python311\\lib\\site-packages (from streamlit) (4.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vignesh t\\appdata\\roaming\\python\\python311\\site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\vignesh t\\appdata\\roaming\\python\\python311\\site-packages (from altair<6,>=4.0->streamlit) (4.21.1)\n",
      "Requirement already satisfied: toolz in c:\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python311\\lib\\site-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python311\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python311\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\vignesh t\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy pulp streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "order_list = pd.read_csv(\"C:\\\\Users\\\\Vignesh T\\\\Downloads\\\\Supply chain logisitcs problem.xlsx - OrderList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "order_list = pd.read_csv(\"C:\\\\Users\\\\Vignesh T\\\\Downloads\\\\Supply chain logisitcs problem.xlsx - OrderList.csv\")\n",
    "freight_rates = pd.read_csv(\"C:\\\\Users\\\\Vignesh T\\\\Downloads\\\\Supply chain logisitcs problem.xlsx - FreightRates.csv\")\n",
    "plant_ports = pd.read_csv(\"C:\\\\Users\\\\Vignesh T\\\\Downloads\\\\Supply chain logisitcs problem.xlsx - PlantPorts.csv\")\n",
    "products_per_plant = pd.read_csv(\"C:\\\\Users\\\\Vignesh T\\\\Downloads\\\\Supply chain logisitcs problem.xlsx - ProductsPerPlant.csv\")\n",
    "vmi_customers = pd.read_csv(\"C:\\\\Users\\\\Vignesh T\\\\Downloads\\\\Supply chain logisitcs problem.xlsx - VmiCustomers.csv\")\n",
    "wh_capacities = pd.read_csv(\"C:\\\\Users\\\\Vignesh T\\\\Downloads\\\\Supply chain logisitcs problem.xlsx - WhCapacities.csv\")\n",
    "wh_costs = pd.read_csv(\"C:\\\\Users\\\\Vignesh T\\\\Downloads\\\\Supply chain logisitcs problem.xlsx - WhCosts.csv\")\n",
    "\n",
    "# Data cleansing function\n",
    "def clean_data(df):\n",
    "    df.dropna(inplace=True)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "# Clean all datasets\n",
    "order_list = clean_data(order_list)\n",
    "freight_rates = clean_data(freight_rates)\n",
    "plant_ports = clean_data(plant_ports)\n",
    "products_per_plant = clean_data(products_per_plant)\n",
    "vmi_customers = clean_data(vmi_customers)\n",
    "wh_capacities = clean_data(wh_capacities)\n",
    "wh_costs = clean_data(wh_costs)\n",
    "\n",
    "# Save cleaned data for further use\n",
    "order_list.to_csv('cleaned_OrderList.csv', index=False)\n",
    "freight_rates.to_csv('cleaned_FreightRates.csv', index=False)\n",
    "plant_ports.to_csv('cleaned_PlantPorts.csv', index=False)\n",
    "products_per_plant.to_csv('cleaned_ProductsPerPlant.csv', index=False)\n",
    "vmi_customers.to_csv('cleaned_VmiCustomers.csv', index=False)\n",
    "wh_capacities.to_csv('cleaned_WhCapacities.csv', index=False)\n",
    "wh_costs.to_csv('cleaned_WhCosts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in order_list: Index(['Order ID', 'Order Date', 'Origin Port', 'Carrier', 'TPT',\n",
      "       'Service Level', 'Ship ahead day count', 'Ship Late Day count',\n",
      "       'Customer', 'Product ID', 'Plant Code', 'Destination Port',\n",
      "       'Unit quantity', 'Weight'],\n",
      "      dtype='object')\n",
      "Columns in wh_costs: Index(['WH', 'Cost/unit'], dtype='object')\n",
      "KeyError during merge: 'Warehouse ID'\n",
      "KeyError during calculation: 'Unit Quantity'\n",
      "CSV file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming order_list and wh_costs are DataFrames and imported pandas as pd\n",
    "\n",
    "# Debugging: Print columns of both DataFrames to ensure 'Warehouse ID' and 'Product ID' exist\n",
    "print(\"Columns in order_list:\", order_list.columns)\n",
    "print(\"Columns in wh_costs:\", wh_costs.columns)\n",
    "\n",
    "# Step 1: Merge order_list with wh_costs\n",
    "try:\n",
    "    order_list = pd.merge(order_list, wh_costs, on=['Warehouse ID', 'Product ID'], how='left')\n",
    "    print(\"Merge successful. Columns in merged DataFrame:\", order_list.columns)\n",
    "except KeyError as e:\n",
    "    print(\"KeyError during merge:\", e)\n",
    "\n",
    "# Step 2: Calculate Historical Cost\n",
    "try:\n",
    "    order_list['Historical Storage Cost'] = order_list['Unit Quantity'] * order_list['Cost per Unit']\n",
    "    order_list['Total Historical Cost'] = order_list['Historical Cost'] + order_list['Historical Storage Cost']\n",
    "    print(\"Calculation of Historical Costs successful.\")\n",
    "except KeyError as e:\n",
    "    print(\"KeyError during calculation:\", e)\n",
    "\n",
    "# Step 3: Save result\n",
    "try:\n",
    "    order_list.to_csv('HistoricalCosts.csv', index=False)\n",
    "    print(\"CSV file saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error saving CSV file:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in order_list: Index(['Order ID', 'Order Date', 'Origin Port', 'Carrier', 'TPT',\n",
      "       'Service Level', 'Ship ahead day count', 'Ship Late Day count',\n",
      "       'Customer', 'Product ID', 'Plant Code', 'Destination Port',\n",
      "       'Unit quantity', 'Weight'],\n",
      "      dtype='object')\n",
      "Order Date conversion successful.\n",
      "KeyError during groupby operation: 'Warehouse ID'\n",
      "daily_orders DataFrame was not created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming order_list and wh_capacities are DataFrames and imported pandas as pd\n",
    "\n",
    "# Debugging: Print columns of order_list\n",
    "print(\"Columns in order_list:\", order_list.columns)\n",
    "\n",
    "# Convert 'Order Date' to datetime\n",
    "try:\n",
    "    order_list['Order Date'] = pd.to_datetime(order_list['Order Date'])\n",
    "    print(\"Order Date conversion successful.\")\n",
    "except KeyError as e:\n",
    "    print(\"KeyError during Order Date conversion:\", e)\n",
    "    order_list['Order Date'] = None  # Ensure the column is set to None in case of error\n",
    "\n",
    "# Ensure 'Order Date' conversion was successful\n",
    "if order_list['Order Date'] is not None:\n",
    "    # Group by 'Warehouse ID' and date to calculate daily orders\n",
    "    try:\n",
    "        daily_orders = order_list.groupby(['Warehouse ID', order_list['Order Date'].dt.date]).size().reset_index(name='Daily Orders')\n",
    "        print(\"Daily orders calculation successful. Columns in daily_orders:\", daily_orders.columns)\n",
    "    except KeyError as e:\n",
    "        print(\"KeyError during groupby operation:\", e)\n",
    "        daily_orders = None  # Ensure the variable is set to None in case of error\n",
    "    except NameError as e:\n",
    "        print(\"NameError during groupby operation:\", e)\n",
    "        daily_orders = None  # Ensure the variable is set to None in case of error\n",
    "\n",
    "    # Ensure daily_orders was created successfully\n",
    "    if daily_orders is not None:\n",
    "        # Debugging: Print columns of wh_capacities\n",
    "        print(\"Columns in wh_capacities:\", wh_capacities.columns)\n",
    "\n",
    "        # Merge daily_orders with wh_capacities\n",
    "        try:\n",
    "            capacity_utilization = pd.merge(daily_orders, wh_capacities, on='Warehouse ID')\n",
    "            print(\"Merge successful. Columns in capacity_utilization:\", capacity_utilization.columns)\n",
    "        except KeyError as e:\n",
    "            print(\"KeyError during merge operation:\", e)\n",
    "            capacity_utilization = None  # Ensure the variable is set to None in case of error\n",
    "        except NameError as e:\n",
    "            print(\"NameError during merge operation:\", e)\n",
    "            capacity_utilization = None  # Ensure the variable is set to None in case of error\n",
    "\n",
    "        # Ensure capacity_utilization was created successfully\n",
    "        if capacity_utilization is not None:\n",
    "            # Calculate capacity utilization\n",
    "            try:\n",
    "                capacity_utilization['Utilization'] = capacity_utilization['Daily Orders'] / capacity_utilization['Capacity (Orders per day)'] * 100\n",
    "                print(\"Calculation of capacity utilization successful.\")\n",
    "            except KeyError as e:\n",
    "                print(\"KeyError during calculation:\", e)\n",
    "\n",
    "            # Save result\n",
    "            try:\n",
    "                capacity_utilization.to_csv('CapacityUtilization.csv', index=False)\n",
    "                print(\"CSV file saved successfully.\")\n",
    "            except Exception as e:\n",
    "                print(\"Error saving CSV file:\", e)\n",
    "        else:\n",
    "            print(\"capacity_utilization DataFrame was not created.\")\n",
    "    else:\n",
    "        print(\"daily_orders DataFrame was not created.\")\n",
    "else:\n",
    "    print(\"Order Date conversion failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in order_list: Index(['Order ID', 'Order Date', 'Origin Port', 'Carrier', 'TPT',\n",
      "       'Service Level', 'Ship ahead day count', 'Ship Late Day count',\n",
      "       'Customer', 'Product ID', 'Plant Code', 'Destination Port',\n",
      "       'Unit quantity', 'Weight'],\n",
      "      dtype='object')\n",
      "Columns in freight_rates: Index(['Carrier', 'orig_port_cd', 'dest_port_cd', 'minm_wgh_qty',\n",
      "       'max_wgh_qty', 'svc_cd', 'minimum cost', 'rate', 'mode_dsc',\n",
      "       'tpt_day_cnt', 'Carrier type'],\n",
      "      dtype='object')\n",
      "First few rows in order_list:\n",
      "      Order ID Order Date Origin Port Carrier  TPT Service Level  \\\n",
      "0  1447296447 2013-05-26      PORT09   V44_3    1           CRF   \n",
      "1  1447158015 2013-05-26      PORT09   V44_3    1           CRF   \n",
      "2  1447138899 2013-05-26      PORT09   V44_3    1           CRF   \n",
      "3  1447363528 2013-05-26      PORT09   V44_3    1           CRF   \n",
      "4  1447363981 2013-05-26      PORT09   V44_3    1           CRF   \n",
      "\n",
      "   Ship ahead day count  Ship Late Day count   Customer  Product ID  \\\n",
      "0                     3                    0  V55555_53     1700106   \n",
      "1                     3                    0  V55555_53     1700106   \n",
      "2                     3                    0  V55555_53     1700106   \n",
      "3                     3                    0  V55555_53     1700106   \n",
      "4                     3                    0  V55555_53     1700106   \n",
      "\n",
      "  Plant Code Destination Port  Unit quantity  Weight  \n",
      "0    PLANT16           PORT09            808   14.30  \n",
      "1    PLANT16           PORT09           3188   87.94  \n",
      "2    PLANT16           PORT09           2331   61.20  \n",
      "3    PLANT16           PORT09            847   16.16  \n",
      "4    PLANT16           PORT09           2163   52.34  \n",
      "First few rows in freight_rates:\n",
      "   Carrier orig_port_cd dest_port_cd  minm_wgh_qty max_wgh_qty svc_cd  \\\n",
      "0  V444_6       PORT08       PORT09         250.0      499.99    DTD   \n",
      "1  V444_6       PORT08       PORT09          65.0       69.99    DTD   \n",
      "2  V444_6       PORT08       PORT09          60.0       64.99    DTD   \n",
      "3  V444_6       PORT08       PORT09          50.0       54.99    DTD   \n",
      "4  V444_6       PORT08       PORT09          35.0       39.99    DTD   \n",
      "\n",
      "  minimum cost      rate mode_dsc  tpt_day_cnt Carrier type  \n",
      "0     $ 43.23    $ 0.71    AIR               2  V88888888_0  \n",
      "1     $ 43.23    $ 0.75    AIR               2  V88888888_0  \n",
      "2     $ 43.23    $ 0.79    AIR               2  V88888888_0  \n",
      "3     $ 43.23    $ 0.83    AIR               2  V88888888_0  \n",
      "4     $ 43.23    $ 1.06    AIR               2  V88888888_0  \n",
      "One or more columns for merging are missing in order_list or freight_rates DataFrame.\n",
      "'Rate' column is missing in order_list DataFrame after merge.\n",
      "CSV file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming order_list and freight_rates are DataFrames and imported pandas as pd\n",
    "\n",
    "# Debugging: Print columns of order_list and freight_rates\n",
    "print(\"Columns in order_list:\", order_list.columns)\n",
    "print(\"Columns in freight_rates:\", freight_rates.columns)\n",
    "\n",
    "# Check for column names and print first few rows for better understanding\n",
    "print(\"First few rows in order_list:\\n\", order_list.head())\n",
    "print(\"First few rows in freight_rates:\\n\", freight_rates.head())\n",
    "\n",
    "# Ensure the necessary columns exist in both DataFrames before merging\n",
    "if 'Historical Route' in order_list.columns and 'Unit Weight' in order_list.columns and 'Destination' in freight_rates.columns and 'Weight Gap' in freight_rates.columns:\n",
    "    # Step 1: Merge order_list with freight_rates\n",
    "    try:\n",
    "        order_list = pd.merge(order_list, freight_rates, left_on=['Historical Route', 'Unit Weight'], right_on=['Destination', 'Weight Gap'], how='left')\n",
    "        print(\"Merge successful. Columns in merged DataFrame:\", order_list.columns)\n",
    "    except KeyError as e:\n",
    "        print(\"KeyError during merge operation:\", e)\n",
    "else:\n",
    "    print(\"One or more columns for merging are missing in order_list or freight_rates DataFrame.\")\n",
    "\n",
    "# Ensure merge was successful before proceeding\n",
    "if 'Rate' in order_list.columns:\n",
    "    # Step 2: Calculate Freight Cost\n",
    "    try:\n",
    "        order_list['Freight Cost'] = order_list['Unit Weight'] * order_list['Rate']\n",
    "        print(\"Calculation of Freight Cost successful.\")\n",
    "    except KeyError as e:\n",
    "        print(\"KeyError during Freight Cost calculation:\", e)\n",
    "else:\n",
    "    print(\"'Rate' column is missing in order_list DataFrame after merge.\")\n",
    "\n",
    "# Save result\n",
    "try:\n",
    "    order_list.to_csv('FreightCosts.csv', index=False)\n",
    "    print(\"CSV file saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error saving CSV file:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in order_list: Index(['Order ID', 'Order Date', 'Origin Port', 'Carrier', 'TPT',\n",
      "       'Service Level', 'Ship ahead day count', 'Ship Late Day count',\n",
      "       'Customer', 'Product ID', 'Plant Code', 'Destination Port',\n",
      "       'Unit quantity', 'Weight'],\n",
      "      dtype='object')\n",
      "Columns in wh_capacities: Index(['Plant ID', 'Daily Capacity'], dtype='object')\n",
      "Columns in vmi_customers: Index(['Plant Code', 'Customers'], dtype='object')\n",
      "Sample order_list named tuple: Pandas(_0=1447296447, _1=Timestamp('2013-05-26 00:00:00'), _2='PORT09', Carrier='V44_3', TPT=1, _5='CRF', _6=3, _7=0, Customer='V55555_53', _9=1700106, _10='PLANT16', _11='PORT09', _12=808, Weight=14.3)\n",
      "Sample wh_capacities named tuple: Pandas(_0='PLANT15', _1=11)\n",
      "Sample vmi_customers named tuple: Pandas(_0='PLANT02', Customers='V5555555555555_16')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m LpProblem(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupply-chain-optimization\u001b[39m\u001b[38;5;124m\"\u001b[39m, sense\u001b[38;5;241m=\u001b[39mLpMinimize)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Define variables\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Replace 'Warehouse_ID' and 'Customer_ID' with actual column names from your DataFrame\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m variables \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWarehouse ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomer ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mLpVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43morder\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWarehouse ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43morder\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomer ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowBound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mContinuous\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43morder_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitertuples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Define the objective function\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Replace 'Historical_Storage_Cost' and 'Freight_Cost' with actual column names\u001b[39;00m\n\u001b[0;32m     26\u001b[0m model \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lpSum(variables[order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarehouse ID\u001b[39m\u001b[38;5;124m'\u001b[39m], order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer ID\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m*\u001b[39m (order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHistorical Storage Cost\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreight Cost\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[0;32m     27\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m order_list\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "Cell \u001b[1;32mIn[17], line 21\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m LpProblem(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupply-chain-optimization\u001b[39m\u001b[38;5;124m\"\u001b[39m, sense\u001b[38;5;241m=\u001b[39mLpMinimize)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Define variables\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Replace 'Warehouse_ID' and 'Customer_ID' with actual column names from your DataFrame\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m variables \u001b[38;5;241m=\u001b[39m {(\u001b[43morder\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWarehouse ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer ID\u001b[39m\u001b[38;5;124m'\u001b[39m]): LpVariable(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morder[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarehouse ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morder[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, lowBound\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, cat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContinuous\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m     22\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m order_list\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)}\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Define the objective function\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Replace 'Historical_Storage_Cost' and 'Freight_Cost' with actual column names\u001b[39;00m\n\u001b[0;32m     26\u001b[0m model \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lpSum(variables[order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarehouse ID\u001b[39m\u001b[38;5;124m'\u001b[39m], order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer ID\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m*\u001b[39m (order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHistorical Storage Cost\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreight Cost\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[0;32m     27\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m order_list\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the DataFrames are already defined\n",
    "print(\"Columns in order_list:\", order_list.columns)\n",
    "print(\"Columns in wh_capacities:\", wh_capacities.columns)\n",
    "print(\"Columns in vmi_customers:\", vmi_customers.columns)\n",
    "\n",
    "# Print a sample of the named tuples\n",
    "print(\"Sample order_list named tuple:\", next(order_list.itertuples(index=False)))\n",
    "print(\"Sample wh_capacities named tuple:\", next(wh_capacities.itertuples(index=False)))\n",
    "print(\"Sample vmi_customers named tuple:\", next(vmi_customers.itertuples(index=False)))\n",
    "\n",
    "from pulp import LpMaximize, LpMinimize, LpProblem, LpStatus, LpVariable, lpSum\n",
    "import pandas as pd\n",
    "\n",
    "# Define the problem\n",
    "model = LpProblem(name=\"supply-chain-optimization\", sense=LpMinimize)\n",
    "\n",
    "# Define variables\n",
    "# Replace 'Warehouse_ID' and 'Customer_ID' with actual column names from your DataFrame\n",
    "variables = {(order['Warehouse ID'], order['Customer ID']): LpVariable(name=f\"x_{order['Warehouse ID']}_{order['Customer ID']}\", lowBound=0, cat='Continuous') \n",
    "             for order in order_list.itertuples(index=False)}\n",
    "\n",
    "# Define the objective function\n",
    "# Replace 'Historical_Storage_Cost' and 'Freight_Cost' with actual column names\n",
    "model += lpSum(variables[order['Warehouse ID'], order['Customer ID']] * (order['Historical Storage Cost'] + order['Freight Cost']) \n",
    "               for order in order_list.itertuples(index=False))\n",
    "\n",
    "# Define constraints\n",
    "# Replace 'Warehouse_ID' and 'Capacity_Orders_per_day' with actual column names\n",
    "for warehouse in wh_capacities.itertuples(index=False):\n",
    "    model += lpSum(variables[warehouse['Warehouse ID'], customer['Customer ID']] \n",
    "                   for customer in vmi_customers.itertuples(index=False) \n",
    "                   if customer['Warehouse ID'] == warehouse['Warehouse ID']) <= warehouse['Capacity (Orders per day)'], f\"Capacity_Constraint_{warehouse['Warehouse ID']}\"\n",
    "\n",
    "# Solve the model\n",
    "status = model.solve()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Status: {LpStatus[model.status]}\")\n",
    "for var in model.variables():\n",
    "    print(f\"{var.name}: {var.varValue}\")\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame([(v.name, v.varValue) for v in model.variables()], columns=['Variable', 'Value'])\n",
    "results.to_csv('OptimizationResults.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n",
      "x_PLANT03_V555555555555555555_17: 0.0\n",
      "x_PLANT03_V555555555555555555_42: 0.0\n",
      "x_PLANT03_V555555555555555555_45: 0.0\n",
      "x_PLANT03_V555555555555555555_46: 0.0\n",
      "x_PLANT03_V555555555555555_23: 0.0\n",
      "x_PLANT03_V555555555555555_29: 0.0\n",
      "x_PLANT03_V555555555555555_44: 0.0\n",
      "x_PLANT03_V55555555555555_8: 0.0\n",
      "x_PLANT03_V5555555555555_16: 0.0\n",
      "x_PLANT03_V555555555555_31: 0.0\n",
      "x_PLANT03_V55555555555_28: 0.0\n",
      "x_PLANT03_V555555555_14: 0.0\n",
      "x_PLANT03_V555555555_27: 0.0\n",
      "x_PLANT03_V555555555_3: 0.0\n",
      "x_PLANT03_V555555555_35: 0.0\n",
      "x_PLANT03_V55555555_0: 0.0\n",
      "x_PLANT03_V55555555_32: 0.0\n",
      "x_PLANT03_V55555555_5: 0.0\n",
      "x_PLANT03_V55555555_7: 0.0\n",
      "x_PLANT03_V5555555_12: 0.0\n",
      "x_PLANT03_V5555555_19: 0.0\n",
      "x_PLANT03_V5555555_22: 0.0\n",
      "x_PLANT03_V5555555_30: 0.0\n",
      "x_PLANT03_V555555_24: 0.0\n",
      "x_PLANT03_V555555_34: 0.0\n",
      "x_PLANT03_V555555_40: 0.0\n",
      "x_PLANT03_V555555_6: 0.0\n",
      "x_PLANT03_V55555_2: 0.0\n",
      "x_PLANT03_V55555_26: 0.0\n",
      "x_PLANT03_V55555_4: 0.0\n",
      "x_PLANT03_V5555_20: 0.0\n",
      "x_PLANT03_V5555_25: 0.0\n",
      "x_PLANT03_V5555_33: 0.0\n",
      "x_PLANT03_V5555_36: 0.0\n",
      "x_PLANT03_V5555_38: 0.0\n",
      "x_PLANT03_V555_15: 0.0\n",
      "x_PLANT03_V555_41: 0.0\n",
      "x_PLANT03_V55_13: 0.0\n",
      "x_PLANT03_V55_37: 0.0\n",
      "x_PLANT03_V55_39: 0.0\n",
      "x_PLANT03_V55_47: 0.0\n",
      "x_PLANT04_V55555_2: 0.0\n",
      "x_PLANT08_V555555555_14: 0.0\n",
      "x_PLANT08_V555555_6: 0.0\n",
      "x_PLANT08_V55555_2: 0.0\n",
      "x_PLANT08_V555_15: 0.0\n",
      "x_PLANT08_V55_13: 0.0\n",
      "x_PLANT09_V55555555555_28: 0.0\n",
      "x_PLANT09_V55555555_7: 0.0\n",
      "x_PLANT12_V555555555555555_29: 0.0\n",
      "x_PLANT12_V55555555555555_8: 0.0\n",
      "x_PLANT12_V5555555555_1: 0.0\n",
      "x_PLANT12_V555555555_3: 0.0\n",
      "x_PLANT12_V55555555_5: 0.0\n",
      "x_PLANT12_V55555555_7: 0.0\n",
      "x_PLANT12_V55555555_9: 0.0\n",
      "x_PLANT12_V555555_11: 0.0\n",
      "x_PLANT12_V555555_24: 0.0\n",
      "x_PLANT12_V555555_6: 0.0\n",
      "x_PLANT12_V55555_10: 0.0\n",
      "x_PLANT12_V55555_2: 0.0\n",
      "x_PLANT12_V5555_33: 0.0\n",
      "x_PLANT13_V5555555555_1: 0.0\n",
      "x_PLANT13_V555555555_3: 0.0\n",
      "x_PLANT13_V55555555_0: 0.0\n",
      "x_PLANT13_V55555555_5: 0.0\n",
      "x_PLANT13_V55555555_7: 0.0\n",
      "x_PLANT13_V555555_6: 0.0\n",
      "x_PLANT13_V55555_2: 0.0\n",
      "x_PLANT13_V55555_4: 0.0\n",
      "x_PLANT16_V555555_6: 0.0\n",
      "x_PLANT16_V55555_4: 0.0\n",
      "x_PLANT16_V55555_53: 0.0\n"
     ]
    }
   ],
   "source": [
    "from pulp import LpMaximize, LpMinimize, LpProblem, LpStatus, LpVariable, lpSum\n",
    "import pandas as pd\n",
    "\n",
    "# Define the problem\n",
    "model = LpProblem(name=\"supply-chain-optimization\", sense=LpMinimize)\n",
    "\n",
    "# Create variables dictionary directly from DataFrame\n",
    "variables = {}\n",
    "for _, order in order_list.iterrows():\n",
    "    variables[(order['Plant Code'], order['Customer'])] = LpVariable(\n",
    "        name=f\"x_{order['Plant Code']}_{order['Customer']}\", lowBound=0, cat='Continuous'\n",
    "    )\n",
    "\n",
    "# Define the objective function\n",
    "model += lpSum(\n",
    "    variables[(order['Plant Code'], order['Customer'])] * (order['Unit quantity'] * order['Weight'])\n",
    "    for _, order in order_list.iterrows()\n",
    ")\n",
    "\n",
    "# Define constraints\n",
    "for _, warehouse in wh_capacities.iterrows():\n",
    "    model += lpSum(\n",
    "        variables.get((warehouse['Plant ID'], customer['Customers']), 0)\n",
    "        for _, customer in vmi_customers.iterrows()\n",
    "        if customer['Plant Code'] == warehouse['Plant ID']\n",
    "    ) <= warehouse['Daily Capacity'], f\"Capacity_Constraint_{warehouse['Plant ID']}\"\n",
    "\n",
    "# Solve the model\n",
    "status = model.solve()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Status: {LpStatus[model.status]}\")\n",
    "for var in model.variables():\n",
    "    print(f\"{var.name}: {var.varValue}\")\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame([(v.name, v.varValue) for v in model.variables()], columns=['Variable', 'Value'])\n",
    "results.to_csv('OptimizationResults.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Capacity (Orders per day)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Capacity (Orders per day)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Scenario with changed warehouse capacities\u001b[39;00m\n\u001b[0;32m      2\u001b[0m new_wh_capacities \u001b[38;5;241m=\u001b[39m wh_capacities\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mnew_wh_capacities\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCapacity (Orders per day)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.1\u001b[39m  \u001b[38;5;66;03m# Increase capacities by 10%\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Repeat optimization with new capacities\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m LpProblem(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupply-chain-optimization\u001b[39m\u001b[38;5;124m\"\u001b[39m, sense\u001b[38;5;241m=\u001b[39mLpMinimize)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Capacity (Orders per day)'"
     ]
    }
   ],
   "source": [
    "# Example: Scenario with changed warehouse capacities\n",
    "new_wh_capacities = wh_capacities.copy()\n",
    "new_wh_capacities['Capacity (Orders per day)'] *= 1.1  # Increase capacities by 10%\n",
    "\n",
    "# Repeat optimization with new capacities\n",
    "model = LpProblem(name=\"supply-chain-optimization\", sense=LpMinimize)\n",
    "variables = {(order['Warehouse ID'], order['Customer ID']): LpVariable(name=f\"x_{order['Warehouse ID']}_{order['Customer ID']}\", lowBound=0, cat='Continuous') for order in order_list.itertuples()}\n",
    "\n",
    "model += lpSum(variables[order['Warehouse ID'], order['Customer ID']] * (order['Historical Storage Cost'] + order['Freight Cost']) for order in order_list.itertuples())\n",
    "\n",
    "for warehouse in new_wh_capacities.itertuples():\n",
    "    model += lpSum(variables[warehouse['Warehouse ID'], customer['Customer ID']] for customer in vmi_customers.itertuples() if customer['Warehouse ID'] == warehouse['Warehouse ID']) <= warehouse['Capacity (Orders per day)'], f\"New_Capacity_Constraint_{warehouse['Warehouse ID']}\"\n",
    "\n",
    "status = model.solve()\n",
    "\n",
    "print(f\"Status: {LpStatus[model.status]}\")\n",
    "for var in model.variables():\n",
    "    print(f\"{var.name}: {var.value()}\")\n",
    "\n",
    "results = pd.DataFrame([(v.name, v.varValue) for v in model.variables()], columns=['Variable', 'Value'])\n",
    "results.to_csv('ScenarioOptimizationResults.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n",
      "x_PLANT03_V555555555555555555_17: 0.0\n",
      "x_PLANT03_V555555555555555555_42: 0.0\n",
      "x_PLANT03_V555555555555555555_45: 0.0\n",
      "x_PLANT03_V555555555555555555_46: 0.0\n",
      "x_PLANT03_V555555555555555_23: 0.0\n",
      "x_PLANT03_V555555555555555_29: 0.0\n",
      "x_PLANT03_V555555555555555_44: 0.0\n",
      "x_PLANT03_V55555555555555_8: 0.0\n",
      "x_PLANT03_V5555555555555_16: 0.0\n",
      "x_PLANT03_V555555555555_31: 0.0\n",
      "x_PLANT03_V55555555555_28: 0.0\n",
      "x_PLANT03_V555555555_14: 0.0\n",
      "x_PLANT03_V555555555_27: 0.0\n",
      "x_PLANT03_V555555555_3: 0.0\n",
      "x_PLANT03_V555555555_35: 0.0\n",
      "x_PLANT03_V55555555_0: 0.0\n",
      "x_PLANT03_V55555555_32: 0.0\n",
      "x_PLANT03_V55555555_5: 0.0\n",
      "x_PLANT03_V55555555_7: 0.0\n",
      "x_PLANT03_V5555555_12: 0.0\n",
      "x_PLANT03_V5555555_19: 0.0\n",
      "x_PLANT03_V5555555_22: 0.0\n",
      "x_PLANT03_V5555555_30: 0.0\n",
      "x_PLANT03_V555555_24: 0.0\n",
      "x_PLANT03_V555555_34: 0.0\n",
      "x_PLANT03_V555555_40: 0.0\n",
      "x_PLANT03_V555555_6: 0.0\n",
      "x_PLANT03_V55555_2: 0.0\n",
      "x_PLANT03_V55555_26: 0.0\n",
      "x_PLANT03_V55555_4: 0.0\n",
      "x_PLANT03_V5555_20: 0.0\n",
      "x_PLANT03_V5555_25: 0.0\n",
      "x_PLANT03_V5555_33: 0.0\n",
      "x_PLANT03_V5555_36: 0.0\n",
      "x_PLANT03_V5555_38: 0.0\n",
      "x_PLANT03_V555_15: 0.0\n",
      "x_PLANT03_V555_41: 0.0\n",
      "x_PLANT03_V55_13: 0.0\n",
      "x_PLANT03_V55_37: 0.0\n",
      "x_PLANT03_V55_39: 0.0\n",
      "x_PLANT03_V55_47: 0.0\n",
      "x_PLANT04_V55555_2: 0.0\n",
      "x_PLANT08_V555555555_14: 0.0\n",
      "x_PLANT08_V555555_6: 0.0\n",
      "x_PLANT08_V55555_2: 0.0\n",
      "x_PLANT08_V555_15: 0.0\n",
      "x_PLANT08_V55_13: 0.0\n",
      "x_PLANT09_V55555555555_28: 0.0\n",
      "x_PLANT09_V55555555_7: 0.0\n",
      "x_PLANT12_V555555555555555_29: 0.0\n",
      "x_PLANT12_V55555555555555_8: 0.0\n",
      "x_PLANT12_V5555555555_1: 0.0\n",
      "x_PLANT12_V555555555_3: 0.0\n",
      "x_PLANT12_V55555555_5: 0.0\n",
      "x_PLANT12_V55555555_7: 0.0\n",
      "x_PLANT12_V55555555_9: 0.0\n",
      "x_PLANT12_V555555_11: 0.0\n",
      "x_PLANT12_V555555_24: 0.0\n",
      "x_PLANT12_V555555_6: 0.0\n",
      "x_PLANT12_V55555_10: 0.0\n",
      "x_PLANT12_V55555_2: 0.0\n",
      "x_PLANT12_V5555_33: 0.0\n",
      "x_PLANT13_V5555555555_1: 0.0\n",
      "x_PLANT13_V555555555_3: 0.0\n",
      "x_PLANT13_V55555555_0: 0.0\n",
      "x_PLANT13_V55555555_5: 0.0\n",
      "x_PLANT13_V55555555_7: 0.0\n",
      "x_PLANT13_V555555_6: 0.0\n",
      "x_PLANT13_V55555_2: 0.0\n",
      "x_PLANT13_V55555_4: 0.0\n",
      "x_PLANT16_V555555_6: 0.0\n",
      "x_PLANT16_V55555_4: 0.0\n",
      "x_PLANT16_V55555_53: 0.0\n"
     ]
    }
   ],
   "source": [
    "from pulp import LpMaximize, LpMinimize, LpProblem, LpStatus, LpVariable, lpSum\n",
    "import pandas as pd\n",
    "\n",
    "# Create a copy with increased capacities\n",
    "new_wh_capacities = wh_capacities.copy()\n",
    "new_wh_capacities['Daily Capacity'] *= 1.1  # Increase capacities by 10%\n",
    "\n",
    "# Define the problem\n",
    "model = LpProblem(name=\"supply-chain-optimization\", sense=LpMinimize)\n",
    "\n",
    "# Define variables\n",
    "variables = {\n",
    "    (order['Plant Code'], order['Customer']): LpVariable(\n",
    "        name=f\"x_{order['Plant Code']}_{order['Customer']}\", lowBound=0, cat='Continuous'\n",
    "    )\n",
    "    for _, order in order_list.iterrows()\n",
    "}\n",
    "\n",
    "# Define the objective function\n",
    "model += lpSum(\n",
    "    variables[(order['Plant Code'], order['Customer'])] * (order['Unit quantity'] * order['Weight'])\n",
    "    for _, order in order_list.iterrows()\n",
    ")\n",
    "\n",
    "# Define constraints with new capacities\n",
    "for _, warehouse in new_wh_capacities.iterrows():\n",
    "    model += lpSum(\n",
    "        variables.get((warehouse['Plant ID'], customer['Customers']), 0)\n",
    "        for _, customer in vmi_customers.iterrows()\n",
    "        if customer['Plant Code'] == warehouse['Plant ID']\n",
    "    ) <= warehouse['Daily Capacity'], f\"New_Capacity_Constraint_{warehouse['Plant ID']}\"\n",
    "\n",
    "# Solve the model\n",
    "status = model.solve()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Status: {LpStatus[model.status]}\")\n",
    "for var in model.variables():\n",
    "    print(f\"{var.name}: {var.varValue}\")\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame([(v.name, v.varValue) for v in model.variables()], columns=['Variable', 'Value'])\n",
    "results.to_csv('ScenarioOptimizationResults.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in new_wh_capacities: Index(['Plant ID', 'Daily Capacity'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Verify column names in new_wh_capacities\n",
    "print(\"Columns in new_wh_capacities:\", new_wh_capacities.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have these DataFrames: order_list, wh_capacities, and vmi_customers\n",
    "\n",
    "# Calculate Capacity Utilization\n",
    "order_list['Order Date'] = pd.to_datetime(order_list['Order Date'])\n",
    "daily_orders = order_list.groupby(['Plant Code', order_list['Order Date'].dt.date]).size().reset_index(name='Daily Orders')\n",
    "capacity_utilization = pd.merge(daily_orders, wh_capacities, left_on='Plant Code', right_on='Plant ID')\n",
    "\n",
    "capacity_utilization['Utilization'] = capacity_utilization['Daily Orders'] / capacity_utilization['Daily Capacity'] * 100\n",
    "\n",
    "# Save result\n",
    "capacity_utilization.to_csv('CapacityUtilization.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "historical_costs = pd.read_csv('HistoricalCosts.csv')\n",
    "capacity_utilization = pd.read_csv('CapacityUtilization.csv')\n",
    "freight_costs = pd.read_csv('FreightCosts.csv')\n",
    "optimization_results = pd.read_csv('OptimizationResults.csv')\n",
    "\n",
    "# Title\n",
    "st.title('Supply Chain Optimization Dashboard')\n",
    "\n",
    "# Historical Costs\n",
    "st.header('Historical Costs')\n",
    "st.dataframe(historical_costs)\n",
    "\n",
    "# Capacity Utilization\n",
    "st.header('Capacity Utilization')\n",
    "st.dataframe(capacity_utilization)\n",
    "\n",
    "# Freight Costs\n",
    "st.header('Freight Costs')\n",
    "st.dataframe(freight_costs)\n",
    "\n",
    "# Optimization Results\n",
    "st.header('Optimization Results')\n",
    "st.dataframe(optimization_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "files = {\n",
    "    'Historical Costs': 'HistoricalCosts.csv',\n",
    "    'Capacity Utilization': 'CapacityUtilization.csv',\n",
    "    'Freight Costs': 'FreightCosts.csv',\n",
    "    'Optimization Results': 'OptimizationResults.csv'\n",
    "}\n",
    "\n",
    "# Function to load data with error handling\n",
    "def load_data(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        return pd.read_csv(file_path)\n",
    "    else:\n",
    "        st.error(f\"File not found: {file_path}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if file is not found\n",
    "\n",
    "# Load datasets\n",
    "historical_costs = load_data(files['Historical Costs'])\n",
    "capacity_utilization = load_data(files['Capacity Utilization'])\n",
    "freight_costs = load_data(files['Freight Costs'])\n",
    "optimization_results = load_data(files['Optimization Results'])\n",
    "\n",
    "# Title\n",
    "st.title('Supply Chain Optimization Dashboard')\n",
    "\n",
    "# Historical Costs\n",
    "st.header('Historical Costs')\n",
    "if not historical_costs.empty:\n",
    "    st.dataframe(historical_costs)\n",
    "else:\n",
    "    st.write(\"No data available for Historical Costs.\")\n",
    "\n",
    "# Capacity Utilization\n",
    "st.header('Capacity Utilization')\n",
    "if not capacity_utilization.empty:\n",
    "    st.dataframe(capacity_utilization)\n",
    "else:\n",
    "    st.write(\"No data available for Capacity Utilization.\")\n",
    "\n",
    "# Freight Costs\n",
    "st.header('Freight Costs')\n",
    "if not freight_costs.empty:\n",
    "    st.dataframe(freight_costs)\n",
    "else:\n",
    "    st.write(\"No data available for Freight Costs.\")\n",
    "\n",
    "# Optimization Results\n",
    "st.header('Optimization Results')\n",
    "if not optimization_results.empty:\n",
    "    st.dataframe(optimization_results)\n",
    "else:\n",
    "    st.write(\"No data available for Optimization Results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cleaned_data.ipynb', 'cleaned_FreightRates.csv', 'cleaned_merged_data.csv', 'cleaned_OrderList.csv', 'cleaned_PlantPorts.csv', 'cleaned_ProductsPerPlant.csv', 'cleaned_VmiCustomers.csv', 'cleaned_WhCapacities.csv', 'cleaned_WhCosts.csv', 'FreightCosts.csv', 'HistoricalCosts.csv', 'HR_Attrition.ipynb', 'Motgage.ipynb', 'OptimizationResults.csv', 'ScenarioOptimizationResults.csv', 'SupplyChain.ipynb', 'Task.ipynb', 'Technocolab_Attrition.ipynb', 'Variate_analysis.ipynb', 'WA_Fn-UseC_-HR-Employee-Attrition.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List files in the current directory to check if 'CapacityUtilization.csv' exists\n",
    "print(os.listdir('.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply Chain Optimization\n",
    "\n",
    "## Project Overview\n",
    "This project aims to develop a Tableau-based analysis model and a Python-based optimization model to optimize the routing of orders from warehouses to customers, ensuring minimal costs while satisfying constraints.\n",
    "\n",
    "## Technologies\n",
    "- Python (Pandas, NumPy, PuLP)\n",
    "- Tableau/Streamlit\n",
    "- Linear Programming\n",
    "\n",
    "## Dataset Description\n",
    "- **OrderList**: Historical order data.\n",
    "- **FreightRates**: Shipping costs and times.\n",
    "- **PlantPorts**: Warehouse and port links.\n",
    "- **ProductsPerPlant**: Warehouse-product relationships.\n",
    "- **VmiCustomers**: Customer-specific warehouse restrictions.\n",
    "- **WhCapacities**: Warehouse maximum order capacities.\n",
    "- **WhCosts**: Storage costs.\n",
    "\n",
    "## Analysis Tasks\n",
    "- Historical Cost Calculation\n",
    "- Capacity Utilization Analysis\n",
    "- Freight Cost Analysis\n",
    "- Optimization Model\n",
    "- Scenario Analysis\n",
    "- Visualization\n",
    "\n",
    "## How to Run\n",
    "1. Clone the repository.\n",
    "2. Install required packages: `pip install pandas numpy pulp streamlit`\n",
    "3. Run the data processing scripts to clean and analyze data.\n",
    "4. Run the optimization model script.\n",
    "5. Launch the Streamlit app: `streamlit run app.py`\n",
    "\n",
    "## Deliverables\n",
    "- **Visualization Dashboard**: Interactive dashboards for key metrics.\n",
    "- **Summary Report**: Detailed analysis and recommendations.\n",
    "\n",
    "## Evaluation Metrics\n",
    "- **Maintainability**: Code structured in modular functions following PEP-8 standards.\n",
    "- **Portability**: Ensuring compatibility across different environments.\n",
    "- **GitHub Repository**: Public repository with a proper README detailing project workflow, execution, and setup instructions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
